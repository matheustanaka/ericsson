# Default values for cdh Chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

imageCredentials:
  cdh:
    repoPath:
    pullPolicy:
    registry:
      url:
  init-wait-for-data-cdh:
    repoPath:
    pullPolicy:
    registry:
      url:
  init-wait-for-xrefs-cdh:
    repoPath:
    pullPolicy:
    registry:
      url:
  rdh-udmap:
    repoPath:
    pullPolicy:
    registry:
      url:

images:
  cdh:
    name: "eric-bss-eb-cdh"
    tag: "22.15.12"
  init-wait-for-data-cdh:
    name: "eric-bss-eb-wait-for-condition"
    tag: "22.15.12"
  init-wait-for-xrefs-cdh:
    name: "eric-bss-eb-wait-for-condition"
    tag: "22.15.12"
  rdh-udmap:
    name: "eric-bss-eb-rdh"
    tag: "22.15.12"

restartPolicy: Always

metadataName: eric-bss-eb-cdh

cdhDeployments:
  # Installation for a deployment, a deployment contains one rdh -udmap container and many cdh container
  # A deployment can be installed multiple times as replica
  # the cdh containers are listed with a type, which is also the start parameter
  # and a list of instances, a separate cdh container will be installed for each entry
  # The instance name will also be the container name in the deployment, so make sure that
  # each instance name is unique within a deployment.
  # NOTE: cdh -H30 should be started only once, so make sure that it is started
  #       - in one deployment only
  #       - with replicaCount 1
  - name: "a0"
    replicaCount: 1
    cdhContainer:
      - type: "a0"
        instances: [ "eric-bss-eb-cdh-a0-1", "eric-bss-eb-cdh-a0-2", "eric-bss-eb-cdh-a0-3", "eric-bss-eb-cdh-a0-4", "eric-bss-eb-cdh-a0-5", "eric-bss-eb-cdh-a0-6", "eric-bss-eb-cdh-a0-7", "eric-bss-eb-cdh-a0-8", "eric-bss-eb-cdh-a0-9", "eric-bss-eb-cdh-a0-10" ]
    # To generate tracefiles, it is necessary set the tracefile name in the variables below.
    # These files will be stored in the log PVC.
    tracingAndLogging:
      # dtaTracefile: "dta.cdh-a0.trc"
      dtaTracefile: ""
      # dxlTracefile: "dxl.cdh-a0.trc"
      dxlTracefile: ""
      # udrTracefile: "udr.cdh-a0.trc"
      udrTracefile: ""
  - name: "a1"
    replicaCount: 1
    cdhContainer:
      - type: "a1"
        instances: [ "eric-bss-eb-cdh-a1" ]
    tracingAndLogging:
      # dtaTracefile: "dta.cdh-a1.trc"
      dtaTracefile: ""
      # dxlTracefile: "dxl.cdh-a1.trc"
      dxlTracefile: ""
      # udrTracefile: "udr.cdh-a1.trc"
      udrTracefile: ""
  - name: "a2"
    replicaCount: 1
    cdhContainer:
      - type: "a2"
        instances: [ "eric-bss-eb-cdh-a2-1", "eric-bss-eb-cdh-a2-2", "eric-bss-eb-cdh-a2-3", "eric-bss-eb-cdh-a2-4", "eric-bss-eb-cdh-a2-5", "eric-bss-eb-cdh-a2-6", "eric-bss-eb-cdh-a2-7", "eric-bss-eb-cdh-a2-8", "eric-bss-eb-cdh-a2-9", "eric-bss-eb-cdh-a2-10" ]
    tracingAndLogging:
      # dtaTracefile: "dta.cdh-a2.trc"
      dtaTracefile: ""
      # dxlTracefile: "dxl.cdh-a2.trc"
      dxlTracefile: ""
      # udrTracefile: "udr.cdh-a2.trc"
      udrTracefile: ""
  - name: "h30"
    replicaCount: 1
    cdhContainer:
      - type: "H30"
        instances: [ "eric-bss-eb-cdh-h30" ]
    tracingAndLogging:
      # dtaTracefile: "dta.cdh-h30.trc"
      dtaTracefile: ""
      # dxlTracefile: "dxl.cdh-h30.trc"
      dxlTracefile: ""
      # udrTracefile: "udr.cdh-h30.trc"
      udrTracefile: ""

# Grace period for POD termination, in which the POD can shut down gracefully.
# After that period, k8s will terminate the POD un-gracefully (SIGKILL).
# Adapt this value in case the POD needs more time to terminate gracefully,
#   e.g. in case the PID remains in table CDH_INSTANCE after POD termination.
# Note, after the POD has terminated gracefully, the terminationGracePeriodSeconds is stopped immediately.
#       So it does not harm to specify a big value here.
terminationGracePeriodSeconds: 60

#DATA_RETRY_TIME, DATA_RETRY_TIME_MAX
#By default, there is no definition for a time interval in which applications try to reconnect to DaTA.
#If you set the environment variable, the value represents the time interval an application waits
#until it tries to reconnect to DaTA.
#Subsequent connection retries are performed under the following conditions:
# - A double time interval has elapsed and has exceeded a maximum of 60 seconds.
# - A double time interval has elapsed and the value specified by DATA_RETRY_TIME_MAX has been exceeded
dataRetry:
  dataRetryTime:
  dataRetryTimeMax:

cdhRacSetup:
  waitTime: 500
  totalWaitTime: 30
  numAttempts: 60

resources:
  limits:
    cpu: 1000m
    memory: 10Gi
  requests:
    cpu: 100m
    memory: 256Mi

rdhUdmap:
  traceLevel: 0
  useSlave: "-useSlave 1"
  dataTimeout: "-w -1"
  optionalParameters: ""
  envVariables:
    shmMaxEnvironments: "20"
    shmMaxSectors: "10"
    shmMaxSegments: "1000"
    shmMinSegmentSize: "65536"
  resources:
    limits:
      cpu: 1
      memory: 5Gi
    requests:
      cpu: 100m
      memory: 64Mi
  tracingAndLogging:
    bscsErrorTimestamp: ""
    # dtaTracefile: "dta.rdh-udmap.trc"
    dtaTracefile: ""
    # dxlTracefile: "dxl.rdh-udmap.trc"
    dxlTracefile: ""
    # udrTracefile: "udr.rdh-udmap.trc"
    udrTracefile: ""

#A local nodeSelector definition has priority over the global definition above.
nodeSelector: {}

# A local affinity definition has priority over the global definition.
# affinity: {}
# Example:
# affinity:
#   nodeAffinity:
#     preferredDuringSchedulingIgnoredDuringExecution:
#     - weight: 50
#       preference:
#         matchExpressions:
#         - key: topology.kubernetes.io/zone
#           operator: In
#           values:
#           - us-east-1a
#     - weight: 50
#       preference:
#         matchExpressions:
#         - key: topology.kubernetes.io/zone
#           operator: In
#           values:
#           - us-east-1b


suffix:

tnsnames:
  bscsdb: '{{ tpl .Values.global.tnsnames.bscsdb . }}'
  rtxdb: '{{ tpl .Values.global.tnsnames.rtxdb . }}'

sqlnet:
  ora: '{{ tpl .Values.global.sqlnet.ora . }}'
