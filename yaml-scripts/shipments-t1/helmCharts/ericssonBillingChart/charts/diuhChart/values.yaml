# Default values for diuhChart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Possible values: 0, 1
replicaCount: 1

imageCredentials:
  eric-bss-eb-diuh:
    repoPath:
    pullPolicy:
    registry:
      url:
  init-wait-for-data:
    repoPath:
    pullPolicy:
    registry:
      url:
  init-wait-for-xrefs:
    repoPath:
    pullPolicy:
    registry:
      url:

images:
  eric-bss-eb-diuh:
    name: "eric-bss-eb-diuh"
    tag: "22.15.12"
  init-wait-for-data:
    name: "eric-bss-eb-wait-for-condition"
    tag: "22.15.12"
  init-wait-for-xrefs:
    name: "eric-bss-eb-wait-for-condition"
    tag: "22.15.12"

# Grace period for POD termination, in which the POD can shut down gracefully.
# After that period, k8s will terminate the POD un-gracefully (SIGKILL).
# Adapt this value in case the POD needs more time to terminate gracefully,
#   e.g. in case the PID remains in table DIUH_PROCESS after POD termination.
# Note, after the POD has terminated gracefully, the terminationGracePeriodSeconds is stopped immediately.
#       So it does not harm to specify a big value here.
terminationGracePeriodSeconds: 60

#DATA_RETRY_TIME, DATA_RETRY_TIME_MAX
#By default, there is no definition for a time interval in which applications try to reconnect to DaTA.
#If you set the environment variable, the value represents the time interval an application waits
#until it tries to reconnect to DaTA.
#Subsequent connection retries are performed under the following conditions:
# - A double time interval has elapsed and has exceeded a maximum of 60 seconds.
# - A double time interval has elapsed and the value specified by DATA_RETRY_TIME_MAX has been exceeded
dataRetry:
  dataRetryTime:
  dataRetryTimeMax:

resources:
  limits:
    cpu: 1000m
    memory: 5Gi
  requests:
    cpu: 100m
    memory: 64Mi

# Customizable start parameters for diuh
# Do not enable diuh deployments and cronjobs with the same Business Unit Id and Family Group Id.
diuhDeployments:
  - name: "single"
    startParameters:
      businessUnitId: 2
      # list with Family Group IDs. e.g.: "1,2,3"
      familyGroupId:
      # Trace Level: 0, 1, 2, 3
      traceModeLevel: 0
    # To generate tracefiles, it is necessary set the tracefile name in the variables below.
    # These files will be stored in the log PVC.
    tracingAndLogging:
      bscsErrorTimestamp: ""
      # dtaTracefile: "dta.diuh.single.trc"
      dtaTracefile: ""
      # dxlTracefile: "dxl.diuh.single.trc"
      dxlTracefile: ""
      # udrTracefile: "udr.diuh.single.trc"
      udrTracefile: ""

# Be aware that diuh CronJobs are disabled (by default) on suspendedCronJobs config.
diuhCronJobs:
  - name: "job-bu2"
    startParameters:
      businessUnitId: 2
      # list with Family Group IDs. e.g.: "1,2,3"
      familyGroupId:
      # Trace Level: 0, 1, 2, 3
      traceModeLevel: 0
    # Twice a day (12:00 pm and 12:00 am).
    schedule: "0 0,12 * * *"
    failedJobsHistoryLimit: 1
    successfulJobsHistoryLimit: 3
    backoffLimit: 0
    # To generate tracefiles, it is necessary set the tracefile name in the variables below.
    # These files will be stored in the log PVC.
    tracingAndLogging:
      bscsErrorTimestamp: ""
      # dtaTracefile: "dta.diuh.single.trc"
      dtaTracefile: ""
      # dxlTracefile: "dxl.diuh.single.trc"
      dxlTracefile: ""
      # udrTracefile: "udr.diuh.single.trc"
      udrTracefile: ""

#A local nodeSelector definition has priority over the global definition above.
#nodeSelector: {}

# A local affinity definition has priority over the global definition.
# affinity: {}
# Example:
# affinity:
#   nodeAffinity:
#     preferredDuringSchedulingIgnoredDuringExecution:
#     - weight: 50
#       preference:
#         matchExpressions:
#         - key: topology.kubernetes.io/zone
#           operator: In
#           values:
#           - us-east-1a
#     - weight: 50
#       preference:
#         matchExpressions:
#         - key: topology.kubernetes.io/zone
#           operator: In
#           values:
#           - us-east-1b

tnsnames:
  bscsdb: '{{ tpl .Values.global.tnsnames.bscsdb . }}'

sqlnet:
  ora: '{{ tpl .Values.global.sqlnet.ora . }}'
